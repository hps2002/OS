# 操作系统无论吞枣

## cpu执行程序的过程
cpu读取程序计数器的值获得指令在内存中的地址，cpu通过控制单元操作地址总线访问内存中的地址，并通知内存设备准备接收数据

数据总线将指令数据传入指令寄存器

程序计数器自增，自增大小和cpu位宽有关

分析指令类型，如果是计算类型的指令就将他分配到逻辑单元执行，如果是存储类型指令将它分配到控制单元执行。

*cpu不断从读取指令、执行指令之间反复循环，直到程序结束。不断循环的过程成为cpu周期*

## cpu缓存一致性
众所周知cpu和内存之前存在缓存，而cpu操作过后的数据也是存放在缓存的cache line中。所以要通过一些机制使得缓存中的数据能够和内存中的数据保持一致性。

有了内存为什么要存在缓存？
因为cpu的速度越来越快，而cpu到内存中取数据的速度相对太慢，所以在靠近cpu的地方设置一个缓存能补偿cpu访问内存的时间差。

有两种机制：写直达和写回
* 写直达是cpu操作完一个数据之后都将他写回内存中，无论他在不在cache，这样费时费力；
* 写回就是解决写直达增加总线负担的问题<br>
写回方法中，新的数据直接写入cache block中，直到“修改过”的cache要被“替换”的时候才将其写入内存。<br>
这样就缩短了总线在内存和cache之间的往返

上面的保持缓存一致性的方法都是基于单核cpu中，在多核cpu中保持缓存一致性要保证两个方面：写传播和事务串行化
**写传播**：让其他的核心知道当前的核心对cache中的数据做出了操作
**事务串行化**：让其他核心知道操作的顺序，需要引入一个锁的概念

可以通过总线嗅探的方法实现写传播和事务串行化，但是总线嗅探中要多次使用广播通知其他cpu，增加总线的负担。

于是使用MESI协议进行优化：
MESI协议是基于总线嗅探的基础上进行优化的，他的本质是一个有限状态机，通过不同状态之间的转化使得能够实现缓存一致性。

MESI标记的cache line有四个状态：
* 已修改（M）：M状态下的cpu已经对这个cache line已经进行修改，但是还没有写入到内存中
* 已失效状态，表示的是这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据。
* 独占和共享状态都代表 Cache Block 里的数据是干净的，也就是说，这个时候 Cache Block 里的数据和内存里面的数据是一致性的。

状态转移：
如果其他核心没有当前的cache block，是独占状态
如果多个核心拥有cache block但是数据是一样的，是共享状态
在共享状态下，某个核心A修改了cache block，核心A的cache block变为已修改，其他的核心变为失效
如果失效状态下要修改cache block，需要通知其他核心将数据写回内存，然后再修改cache block；

## 缓存伪共享
缓存伪共享问题出现在多核cpu中

什么是缓存伪共享？
假设有两个单独变量a、b，且a、b在内存上的物理地址连续所以a、b在读取的时候可能会在同一个缓存块中被读进cpu，核心A读取变量a、核心B读取变量b。根据cpu读取数据的规则：变量a存放在核心A的cache line中，同时核心A中的cache line也存在变量b； 变量b存放在核心B的cache line中，同时核心B的cache line中也存在变量a。
如果核心A对变量a进行修改，那么根据MESI协议要保证缓存一致性，会使得核心B中存放变量a、b的cache line失效，而核心B下一步要对变量b进行修改，那么要通知核心A将存放变量a、b的cache line写入内存中，核心B重新读取，并进行修改。如果核心A和核心B反复的出现这种操作，会使得MESI协议失效。导致cpu的性能下降

这就是缓存为共享。

解决缓存伪共享：
通过对变量a、b设置为cache line对齐，那么在cpu读取的时候就不会将两个变量读进同一个cache line中了，也就不出现上述的问题。

拓展：在c++中编译器对结构体中的变量进行内存对齐也是这个道理，为了增加cpu的吞吐量，所以要进行内存对齐，避免cpu频繁的读写内存。

## cpu选择线程
cpu选择如何选择线程，这是一个cpu调度问题：
在linux中，调度的对象是一个task_struct的数据结构。

在linux中，每个cpu都有自己的运行队列，其中又包括三个运行队列，dl_rq、rt_rq、cfs_rq优先级从高到低。

## 软中断
中断是计算机响应硬件请求的机制，操作系统接收到硬件的中断请求，会打断正在进行的进程，然后调用内核的中断处理程序来响应请求。

操作系统处理中断的过程要求短且快，避免过长的时间影响操作系统正常的调度，而且处理中断时间，中断请求出于关闭状态，所以中断处理程序执行过长的话会导致其他设备的中断请求丢失。

于是linux系统中提出了软中断的方法，来避免中断处理程序执行过长的时间和中断丢失的问题，将中断处理分成两个阶段完成，分别是上半部分和下半部分：
* **上半部分用于快速处理中断**，一般用来处理跟硬件紧密相关的事情和与时间相关的事情
* **下半部分用来延迟处理上半部分未完成的工作**，以内核线程的形式运行。

因此上半部分是**硬中断**， 下半部分是**软中断**

举个例子：
网卡通过DMA的方式接收网络包之后，将数据写入内存，然后通过**硬件中断**请求通知内核有新的数据到达，内核通过中断处理程序响应当前的中断请求，中断处理的过程分为两个部分：内核禁用网卡的中断，避免频繁硬中断，然后内核触发软中断，将耗时耗力的工作交给软中断处理程序。

硬中断会打断cpu正在执行的任务，立即处理中断程序；而软中断以内核线程的方式执行，不会直接打断cpu执行的任务。

**拓展**
linux中查看软中断运行情况的命令:cat /proc/softirqs
linux中查看硬中断运行情况的命令:cat /proc/interrupts

## 0.1 + 0.2 != 0.3
因为精度丢失的问题所以计算机中的小数小数相加可能不等于数学理论中的值。

计算机中存放小数是采取IEEE 754协议进行存放，一位符号位 + 8位指数位 + 23位尾数位置这是单精度浮点数

双精度浮点：一位符号位 + 11位指数位 + 52位尾数

对于0.1这种十进制的小数转化位二进制会出现无限循环的情况，但是存放在4个字节的float类型中肯定是要截取的，所以后面不能保存下来的数值就是精度丢失。

所以对于那种转化之后精度丢失的数只能取近似值，所以0.1 + 0.2 在计算机系统里面是不等于0.3的，只是最后的结果将近似值等于三而已。

## windows内核和linux内核的区别
内核其实是硬件和用户的接口


linux使用的是宏内核，就是将进程调度、线程调度、中断处理、硬件驱动等归为内核管理，同时linux允许驱动内核模块化。可执行文件是ELF格式<br>
linux内核理念是多任务、对称多处理、可执行文件链接格式、宏内核

windows使用的是混合内核，内核中存在一个小型的内核，其他模块在这个基础上搭建。可执行文件是PE

## 内存管理
逻辑地址：程序编译之后在段中管理的地址；
虚拟地址：通过段式内存管理映射的地址，也叫线性地址；
物理地址：在内存中的真实地址

### 分段
将程序的地址分成一段一段的，如代码段、数据段、堆段...

分段机制下虚拟地址组成：段选择银子 + 段内偏移量

通过段号查找段表，获得段基址，然后加上段内偏移量得到物理地址；

分段机制存在外部内存碎片的问题，因为在分段之后可能会存在一些不连续的小内存块，这时候没有办法被分配。要采取内存交换的方式进行分配，将某一块内存写到硬盘中，再读回来拼接到连续的内存地址上。不过这种方法如果出现程序较大的情况，会卡顿。所以效率十分低下。

### 分页机制
分页机制将物理内存划分为一个个页面，使用页面装载程序。

二级分页机制下的虚拟地址：一级页表号 + 二级页表号 + 页内偏移量

操作系统给程序分配内存的时候只分配一些内存，通过缺页中断进行置换的方法使得小内存运行大程序。

二级页表节省内存？如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。

为了解决页表多次转换影响效率，加入了TLB，页表缓存/快表，里面存放常用的页表项

### 段页式机制
* 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
* 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页

段页式机制：段号 + 段内页号 + 页内偏移

段页式机制地址转换：
* 第一次访问段表，得到页表起始地址；
* 第二次访问页表，得到物理页号；
* 第三次将物理页号与页内位移组合，得到物理地址。

### linux内存管理
Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。

Linux的内存分布

每个程序分为内核空间和用户空间，程序之间有独立的虚拟内存，但是内核空间中关联物理地址是相同的，方便进入内核态之后访问内核空间的内存。

linux用户空间的分布：
* 内核空间，出于最高地址位在32位操作系统中内核空间大小位1G；
* 栈，存放局部变量、函数调用的上下文。栈大小一般为8M；
* 文件映射区， 包括动态库，共享内存等
* 堆，包括动态分配的内存，由低地址向上增长
* BSS， 包括位初始化的静态变量和全局变量；
* 数据段，包括已初始化的静态变量和全局变量
* 代码段，包括二进制的可执行代码
* 保留区，因为小数值地址不合法，防止程序出现bug使得程序跑飞了

### 虚拟内存的作用
第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。

第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。

第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。

### 内存满了？
程序申请内存后，在虚拟内存中进行内存的分配，待到程序读到这块寻内存的时候，cpu访问虚拟地址，发现并没有被映射到物理内存上，于是发生了缺页中断，进程进入内核态，将缺页中断交给内核的缺页中断处理函数进行处理。缺页中断判断是否由合适的空余的物理内存，如果由就分配物理内存。

如果没有物理内存就进行内存回收工作，主要通过两种方式：后台内存回收、直接内存回收

内存回收之后还是没有内存，出发OOM机制通过算法选择一个程序杀死，直到由空余的物理内存。

可以被回收的内存：文件页和匿名页
* 文件页面：回收干净的页面是直接释放、回收脏页面要写回磁盘再进行释放，有I/O操作会影响性能。
* 匿名页面：堆栈中的数据，Linux中通过Swap机制写入交换区，有I/O操作会影响性能

回收两种页面都是基于LRU算法进行，维护双向链表active_list和inactive_list

#### 内存回收的影响
后台回收唤醒kswapd线程进行异步操作，不会阻塞进程。

直接回收，通过同步的方式进行回收，会阻塞进程，导致造成长时间的延迟，使得cpu负载飙升

针对回收内存导致的性能影响解决方案：
* linux中可以通过```/proc/sys/vm/swappiness```选项调整文件页和匿名页的回收倾向。swappiness的范围是0 - 100，数值越高越倾向回收匿名页，一般设置0，但是要注意设置0并不表示不回收匿名页。
* 尽早启动内存回收，Linux中当物理内存到达页低阈值的时候开始进行后台内存回收，到达最小阈值的时候开始进行直接内存回收。页高阈值和页低阈值都是通过最小阈值```/proc/sys/vm/min_free_kbytes```进行计算，所以可以通过调整最小阈值让系统尽早进行内存回收，但是这样会造成内存浪费。
* 在NUMA架构下调整内存回收策略，将```/proc/sys/vm/zone_reclaim_mode```设置为0，使得在回收每个Node本地内存之前寻找其他Node是否有空闲内存。

#### OOM机制杀死进程
如果在内存回收之后还是出现内存不够的情况就会触发OOM机制进行内存杀死，OOM killer 就会根据每个进程的内存占用情况和 oom_score_adj 的值进行打分，得分最高的进程就会被首先杀掉。

我们可以通过调整进程的 ```/proc/[pid]/oom_score_adj``` 值，来降低被 OOM killer 杀掉的概率。调整成-1000，当前进程不会被杀死。

### malloc如何分配内存
malloc如何分配内存？

malloc分配的是虚拟内存，当程序调用的时候会触发缺页中断

malloc()是一个C库函数，还需要系统调用进行mmap()或者brk()进行内存分配
* 当申请内存大于等于128k使用mmap()在文件映射区分配内存，free()之后归还操作系统。当执行malloc(1)的时候，会预分配较大的空间作为内存池。
* 当申请内存小于128k使用brk()在堆中进行分配，free()之后暂时不归还操作系统，停留在内存池中等待下一次分配

为什么不全部使用mmap()进行分配?

使用mmap()分配要进入内核态，频繁的状态切换会对性能造成影响。如果都用mmap()进行内存分配相当于每次都要执行系统调用。而且mmap()在释放后会归还操作系统，所以每次使用mmap()分配的内存在第一次被访问的时候就会出现缺页中断。因此通过brk()进行改进，brk()也是系统调用，不过brk()在第一次调用的时候就预分配较大的内存进入内存池，而且在free()释放内存会也不归还操作系统，而是缓存在内存池中等待下一次分配。

为什么不全部使用brk()进行分配？

brk()虽然可以通过内存池机制减少缺页中断和系统调用次数，但是如果每次申请大空间的内存会导致，小内存块出现`内存泄露`的情况，且valgrind检测不出来。


free()传入首地址，怎么知道删除多大的内存？

malloc分配内存时，返回给用户态的内存起始地址比进程的堆空间的起始多16字节。free()会向左偏移16字节，根据内存块头信息分析当前要释放内存块的大小。

### 在物理内存4G的机器上申请8G的内存？
申请超过物理内存的空间，要经过以下条件的限制才能判断是否申请：操作系统是32位、还是64位，操作系统有没有开启swap机制。


申请的物理内存要看操作系统，如果是32位的操作系统是无法申请大小位8G的内存的，因为32位的操作系统中，用户空间只有4G。所以最多只能申请4G；

在64位的操作系统中用户空间高达128T，所以在能在4G的物理空间上申请8G（注意申请空间不代表访问申请空间只是在虚拟内存中描述申请的空间，并没有将申请的空间映射到物理内存上，根据程序的局限性，只有在cpu访问当前页面的时候才将虚拟地址映射到物理内存中）。

那64位的操作系统能否申请128T的空间？要分情况讨论：开启swap机制和不开始swap机制、物理空间的实际大小
* 如果物理空间足够容纳`申请128T空间`这个过程中程序的开销，那么不开启swap机制也能申请128T的空间。
* 如果物理空间不能容纳`申请128T空间`这个过程中程序的开销，那么就要开启swap机制才能申请128T的空间。否则在申请的过程中会因为开销过大，触发OOM机制把当前的程序kill掉。

特别要注意，可以申请超过物理空间的空间，但是不能载入超过物理内存的空间。换句话说，举个例子能够使用malloc申请超过物理内存的空间，但是不能通过memset访问所有内存。

### 如何避免预读失效和缓存污染问题
**面经：操作系统读取磁盘上的数据会额外多读取一些到内存中，但这些数据没用到，有什么改善的方法？**<br>
**面经：批量读取数据的时候，可能会把热点数据挤出去，有什么改善方法？**

#### 预读失效
操作系统读取请求页面的时候会额外的读取多几个页面进去内存中，以此提高内存吞吐量和缓存命中率

操作系统原生的机制是通过LRU算法，将数据页面读取进去并将最久未使用的页面弹出。但是这样就会出现一些数据没用到，占着茅坑不拉屎的情况。

在Linux中改善预读失效，建立两个队列实现LRU算法，活跃队列（存放热点数据页面）和非活跃队列：在读取页面进去的时候，先是存放到非活跃队列的对头，如果队列满了的话从队尾挤出非活跃队列中的最久未使用页面。当内存命中之后将该页面放进活跃队列的对头。在活跃队列中被寄出去的页面进入非活跃队列的对头。

MySQL中改善预读失效，在LRU队列中以63 : 37的比例设置young区和old区，在磁盘上读取地时候将页面逐个放进old区队头，当命中之后放进young的队头。被young挤出的热点数据进入old的队头。

Linux和MySQL这样的机制只能改善预读失效的问题，但是不能解决缓存污染的问题：

**缓存污染**：从磁盘上读取的页面只访问了一次，但是这些页面把原来队列中的热点数据挤出去了。导致出现频繁的I/O读写。

Linux解决缓存污染：在非活跃队列中的数据只有命中两次才能升级放到活跃队列队头中。

MySOL解决缓存污染：在old区中的数据只有两次命中的时间大于1s才能放到young的队头中。

## 进程
进程指的是在装载进内存中的二进制可执行文件，正在运行中的程序。

1、进程的状态

进程的状态包括：创建状态、就绪状态、就绪挂起、运行状态、阻塞状态、阻塞挂起、结束状态：
* 创建状态：一个进程刚被创建出来的状态：操作系统分配PCB、以及其资源
* 就绪状态：进程进入就绪队列，等待被CPU执行
* 就绪挂起：在就绪队列中暂时被转移进硬盘，但是唤醒进入内存之后能立刻被调度运行。
* 运行状态：进程在cpu上执行的状态。
* 阻塞状态：进程等待某个资源才能继续运行，停下等待该资源的状态。
* 阻塞挂起：阻塞状态中提高cpu效率，将阻塞的进程暂时换出硬盘进行挂起。
* 结束状态：进程运行完成。

2、进程的控制结构

PCB是进程控制块的唯一标识，包括进程标识符（pid）、用户标识符（主要为共享和保护服务）、进程当前状态（运行？就绪？还是阻塞）、进程优先级、上下文信息（cpu相关信息，包括每个寄存器中的值，在进行上下文切换的时候能接着上一次运行的顺序继续下去）

PCB通过链表的方式进行组织形成各种队列，位于操作系统中：如，就绪队列，阻塞队列等。

3、进程创建、终止、阻塞、唤醒

**创建：**，操作系统允许在一个进程中创建另外一个进程，进程创建的时候首先申请一个空白的PCB然后向里面填写控制信息，然后分配资源（可以从父进程中继承，拷贝，也能重新分配），最后进入就绪队列

**终止**，子进程被终止后将来自父进程的资源归还父进程。如果父进程被终止，子进程称为孤儿进程，会被1号进程收养，并由1号进程回收其资源。进程终止过程：查找该进程的pcb、检查进程的运行状态，如果正在运行则打断运行、如果有子进程将子进程交管1号进程、回收进程的资源、将PCB删除

**阻塞**，等待某事件完成，进程可以自己将自己阻塞，但是必须通过其他进程进行唤醒。阻塞的过程：如果正在运行则打断、进程状态变为阻塞、保护现场（修改PCB中包含CPU的相关信息），将PCB放进阻塞队列

**唤醒**，当进程期待的事情发生，能够被其他进程唤醒。唤醒进程：阻塞队列中找到PCB，进程状态变为就绪，进入就绪队列

4、进程上下文切换

一个进程切换另一个进程运行，称为上下文切换；

进程上下文：包含了虚拟内存、栈、堆等用户空间的资源和内核堆栈、寄存器等内核空间的资源。

进程切换的时候操作系统要帮CPU设置好上下文才能保证正常运行。

进程切换模型：进程1在运行的时候准备进行上下文切换，此时进程1会将当前上下文的信息保存在PCB中，切换进来的进程2在在pcb中加载进程2的上下文，再执行进程2。

进程切换的场景：进程的时间片耗尽、当前进程被阻塞、当前进程所需内存不足、被操作系统挂起，睡眠函数sleep的作用、发生硬件中断时进程被打断处理硬件中断。

5、线程

线程是进程当中的一个执行流程，一个进程可以有多条线程，线程之间共享进程的数据和代码、文件等资源。同一个进程内的线程之间的有独立的栈和寄存器用来切换上下文。线程和进程的不同之处在于，线程是调度的基本单位、进程是资源的拥有的基本单位。进程为线程提供资源共享，线程拥有自己的寄存器和栈，线程与进程拥有就绪、堵塞、运行的状态，线程能减少并发执行时间和开销。

线程比进程性能好的地方体现在：创建、运行、上下文切换、线程间数据交换
* 线程创建的时间比进程创建的时间短，因为线程共享进程的资源，只需要创建进程的TCB、寄存器、栈等必须资源即可。
* 线程终止的时间比进程快，因为释放的资源比内存少。
* 线程上下文切换的时候比进程的上下文切换快，因为线程的上下文切换不需要切换页表，线程间具有相同的地址空间，共享进程的页表。
* 因为线程之间共享进程的数据，所以线程之间交换数据不需要经过内核。

6、线程上下文切换

在同一个线程内的上下文切换只需要保存线程中的栈和寄存器等不共享的数据即可，不在同一个进程中的线程切换就相当于进程切换上下文。

7、线程实现

线程主要有三种实现方式：用户线程、内核线程、轻量型进程

用户线程指的是：在用户空间中基于用户态的线程库进行管理，线程控制块在库中实现，操作系统无法看到TCB，只能看到整个进程的PCB；用户线程的调度由用户级库函数直接完成线程的管理。**优点**：每个进程中都由线程控制块列表，TCB由用户及库函数维护，用于不支持线程技术的操作系统。线程切换都是在用户态中，速度快。**缺点**:一个线程阻塞全部线程阻塞，因为操作系统无法调度；用户态线程无法打断正在运行中的线程，只能有他主动交出运行权限，进程中的其他线程只能等待；时间片分给进程中，再分给线程，导致线程的运行时间非常短。

内核线程：内核线程由操作系统进行管理。优点？缺点？

轻量型用户线程（协程）：与内核线程一一对应，（感觉上是用户线程和内核线程的接口该线程帮用户线程与内核线程进行连接，用来管理用户线程）但是又和协程有点相似，需要弄懂才行

8、调度
**抢占式调度**和**非抢占式调度**

调度原则：CPU利用率（越大越好）、系统吞吐量（越大越好）、周转时间（越短越好）、等待时间（越小越好）、响应时间（越小越好）

## 进程通信
进程通信可以通过：管道、消息队列、信号量、信号、socket

管道（匿名管道和命名管道FIFO）：管道只能单向传播信息，两个进程之间要建立两个管道；

消息队列：发送方接收方约定好发送的消息和类型，通过将数据打包传输到队列上，发送方能一直发送，接收方从队列中获取。消息队列不适合大数据传输，因为大小限制。

共享内存：进程间使用一块虚拟空间映射到相同的物理内存中，但是要保证每次操作共享内存的互斥性， P V操作。

信号量：通过信号量进行进程间的互斥操作，同步操作。

信号：给进程发送信号，进程执行对应的操作。可以自定义信号操作函数（捕捉信号，自定义信号函数），否则就执行操作系统的默认操作函数，**SEGSTOP（强制暂停）**和**SIGKILL（强制结束）** 不能无法被忽略（阎王要你三更死，谁敢留你到五更）

socket：通过套接字进行通信，包括不同主机间进程通过TCP或者UDP数据包进行通信，同主机下绑定一个本地文件进行字节流或者数据报进行通信。

## 线程冲突

互斥：临界区只能一个线程获取，其他线程不能获取；

同步：线程在执行过程中相互等待，相互制约

通过锁来进行临界区的互斥，锁的本质是**测试设置**操作
```
核心函数：

int TestAndSet(int *oldset, int new)
{
    int old = *oldset;
    oldset = new;
    return old;
}
```

锁分为忙等待和无等待锁

忙等待锁：一直进行while循环直到获取资源，不让出时间片

无等待锁：请求资源被其他的进程占用，不在cpu上等待，而是进入锁的等待队列，等待被唤醒。保存上下文，让出cpu。

信号量：P/V操作；
```
P操作：
void P(sem_t sem)
{
    sem --;
    if (sem >= 0) 
        获取资源
    else 
        进入阻塞队列
}
V操作：
void V (sem_t sem)
{
    sem ++;
    if (sem <= 0)
        通知等待队列有资源可用
    else 
        仅释放资源
}
```

同步问题：哲学家就餐、读者-写者问题。


**避免死锁**

产生死锁的条件：互斥条件、持有并等待条件、不可剥夺条件、环路等待条件

避免死锁破坏其中一个条件即可，常用的死锁破坏条件是顺序分配资源，以此破坏环路等待条件。

### 悲观锁与乐观锁

悲观锁：操作资源前先上锁，再操作资源。如互斥锁、自旋锁、读写锁

乐观锁：先操作资源，再判断是否有冲突，发生冲突时人为解决冲突

CAS锁是乐观锁，因为它是用期望值来与内存中的值进行比较是否相等，相当于操作了资源之后再判断有无冲突。但是基于CAS的自旋锁是悲观锁，因为它是基于CAS来获得锁。

### 一个进程最多能创建多少线程
一个进程创建的线程数受到操作系统和硬件的限制。

操作系统会限制进程创建的线程数：在32位的Linux操作系统中，虚拟地址空间中的用户空间位3G大小，而创建一个线程的大小还收到操作系统分配给线程的栈空间大小，3G的用户空间理论上能创建的线程数量为300个左右。

**假设内存无限大**，64位的操作系统能创建的线程大小理论上为 **128T** / **分配给线程栈空间的大小（操作系统决定）**。

但是在linux中进程创建的空间还会收到操作系统参数`Threads-max`的影响，还有分配栈空间的参数`stack-size`的影响，以及参数`max_map_count`的影响，还有硬件内存的影响，创建线程的时候线程控制块会随着线程分配的数量呈正相关增长.

### 线程崩溃了进程也会崩溃吗？
如果是在C/C++中线程崩溃了会影响进程崩溃，在java项目中线程崩溃不会引起进程崩溃。

线程崩溃的原因之一：非法访问内存（访问不存在的内存、访问内核地址、对只读空间进行写操作）

非法访问内存引起线程崩溃之后，是会引起进程崩溃的，因为线程出现了内存非法访问，说明进程的内存访问存在不确定性，所以操作系统通过向进程发送信号使得进程非正常停止。

发送信号的过程：调用kill向进程发送信号，非法访问的进程收到操作系统的`11`信号SIGSEGV，进程将控制权限交给操作系统，操作系统根据信号处理函数执行完之后让程序退出。

在收到退出信号后也可以使用sigsetjmp、siglongjmp让进程恢复运行。

在java中发生了`StackoverflowError` 和 `NPE` 这两个非法访问内存的错误线也不会导致进程崩溃的原因是：线程出现崩溃的时候操作系统发送了kill -11信号，但是在信号处理函数中做了额外的处理让线程恢复运行，并且抛出异常。如果对于kill -11信号没有做额外处理生成crash文件。

## 文件系统
